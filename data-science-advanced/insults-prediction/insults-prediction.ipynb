{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Insults in Social Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pbs.twimg.com/media/CkEyfjKUUAURpd9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')\n",
    "training_data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data['cleaned_comment'] = training_data['Comment'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), stop_words='english', max_features=50000)\n",
    "count_vectorizer.fit(training_data['cleaned_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = count_vectorizer.transform(training_data['cleaned_comment'])\n",
    "y = training_data['Insult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = [bool(np.random.binomial(1, .75)) for _ in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[np.array(mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[mask].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[~mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, p=.75):\n",
    "    mask = np.array([bool(np.random.binomial(1, p)) for _ in range(X.shape[0])])\n",
    "    \n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "    X_validation = X[~mask]\n",
    "    y_validation = y[~mask]\n",
    "    \n",
    "    return X_train, y_train, X_validation, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_validation, y_validation = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_predictions = np.zeros(predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "predictions = model.predict(X_validation)\n",
    "validation_score = accuracy_score(y_validation, predictions)\n",
    "\n",
    "print('Validation Score:', validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_validation_score = accuracy_score(y_validation, baseline_predictions)\n",
    "\n",
    "print('Validation Score:', baseline_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember, everything is a hyper-parameter.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PredictionPipeline:\n",
    "    \n",
    "    def __init__(self, ngram_range, vectorizer_class, model_class, training_data):\n",
    "        self.ngram_range=ngram_range\n",
    "        self.vectorizer_class=vectorizer_class\n",
    "        self.model_class=model_class\n",
    "        self.training_data=training_data\n",
    "        self.vectorizer = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.model = None\n",
    "        self.validation_score = None\n",
    "        \n",
    "    def run(self):\n",
    "        self._fit_vectorizer()\n",
    "        self._featurize_text()\n",
    "        self._split_train_and_validation_sets()\n",
    "        self._fit_model_on_training_data()\n",
    "        self._validate_model_on_validation_set()\n",
    "        \n",
    "        print(\n",
    "            \"\"\"\n",
    "            Vectorizer Class: {vectorizer_class}\\n\\\n",
    "            N-gram Range: {ngram_range}\\n\\\n",
    "            Model Class: {model_class}\\n\\\n",
    "            Validation Score: {validation_score}\n",
    "            \"\"\".format(\n",
    "\n",
    "            vectorizer_class=repr(self.vectorizer_class.__name__), \n",
    "            ngram_range=self.ngram_range, \n",
    "            model_class=repr(self.model_class.__name__), \n",
    "            validation_score=round(self.validation_score, 4)\n",
    "\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _fit_vectorizer(self):\n",
    "        self.vectorizer = vectorizer_class(analyzer='word', ngram_range=ngram_range, \n",
    "                                     stop_words='english', max_features=50000)\n",
    "        self.vectorizer.fit(self.training_data['cleaned_comment'])\n",
    "    \n",
    "    def _featurize_text(self):\n",
    "        self.X = self.vectorizer.transform(self.training_data['cleaned_comment'])\n",
    "        self.y = self.training_data['Insult']\n",
    "\n",
    "    def _split_train_and_validation_sets(self):\n",
    "        self.X_train, self.y_train, self.X_validation, self.y_validation = split_data(\n",
    "            self.X, self.y)\n",
    "\n",
    "    def _fit_model_on_training_data(self):\n",
    "        self.model = self.model_class()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def _validate_model_on_validation_set(self):\n",
    "        predictions = self.model.predict(self.X_validation)\n",
    "        self.validation_score = accuracy_score(self.y_validation, predictions)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for ngram_range in [(1, 1), (1, 2), (1, 3), (1, 4)]:\n",
    "    for vectorizer_class in [CountVectorizer, TfidfVectorizer]:\n",
    "        for model_class in [LogisticRegression, LinearSVC, RandomForestClassifier]:\n",
    "            \n",
    "            # run prediction pipeline\n",
    "            prediction_pipeline = PredictionPipeline(\n",
    "                ngram_range=ngram_range,\n",
    "                vectorizer_class=vectorizer_class,\n",
    "                model_class=model_class,\n",
    "                training_data=training_data\n",
    "            )\n",
    "            \n",
    "            prediction_pipeline.run()\n",
    "            \n",
    "            # add hyper-parameters to `results` dictionary\n",
    "            results[str(prediction_pipeline.validation_score)] = {\n",
    "                    'vectorizer_class': prediction_pipeline.vectorizer_class,\n",
    "                    'ngram_range': prediction_pipeline.ngram_range,\n",
    "                    'model_class': prediction_pipeline.model_class\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_3_scores = sorted(results.keys(), reverse=True)[:3]\n",
    "\n",
    "for score in top_3_scores:\n",
    "    print('Score: {score}\\nParameters: {parameters}\\n'.format(\n",
    "        score=score, parameters=results[score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_score_key = top_3_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_class = results[top_score_key]['vectorizer_class']\n",
    "ngram_range = results[top_score_key]['ngram_range']\n",
    "model_class = results[top_score_key]['model_class']\n",
    "\n",
    "# fit vectorizer\n",
    "vectorizer = vectorizer_class(analyzer='word', ngram_range=ngram_range, stop_words='english', max_features=50000)\n",
    "vectorizer.fit(training_data['cleaned_comment'])\n",
    "\n",
    "# transform text\n",
    "X = vectorizer.transform(training_data['cleaned_comment'])\n",
    "y = training_data['Insult']\n",
    "\n",
    "# fit model on training data\n",
    "model = model_class()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    input_string = input('Please enter a string: ')\n",
    "    input_string = clean_text(input_string)\n",
    "    x_test = vectorizer.transform([input_string])\n",
    "    \n",
    "    prediction = model.predict(x_test)[0]\n",
    "    print('Insult?: {}'.format( bool(prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
